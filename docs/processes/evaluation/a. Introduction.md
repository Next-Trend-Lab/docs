---
aliases:
- evaluating
- evaluation
---

![[evaluating.png]]

# **Introduction**  
## **Essence**  
Evaluation, for us, is not a static measure of success but a living [[practice]] of listening to the pulse of systems. It is how communities learn to dance with complexity, attuning to the rhythms of social relationality, ecological vitality, cultural wisdom, governance systems and emergent possibility. At Prisma, we see evaluation as the *essence of organisational development*—a way for collectives to sense, adapt, and evolve their actions in harmony with the essence of [[place]] and the [[Living Systems Principles]] that bind us all. 

### Vision
To redefine evaluation as a dynamic dialogue with life itself—a socio-technological practice that illuminates the flows of value that drive collective evolution.  

### Mission
To deploy and grow a technology-enabled general framework that adapts to [[place]] & [[practice]] through honoring energy flow in its [multi-capital](Multi-Capitals Framework) forms and provides insight into evolution across a system's [[g. Five Spheres of Evaluation|five spheres]], empowering communities to steward regenerative futures.  

### **Values**  
Our approach is built on the foundations of the following four pillars:  
1. **Playfulness**: Everything is an experiment - true emergence is a factor of trying out different approaches and tools.  
2. **Curiosity**: We seek patterns, not endpoints, embracing the unpredictable alchemy of action-learning journeys.
3. **Interdependence**: Every metric is a thread in a larger tapestry, woven from relationships between people, place, and practice. 
4. **Integrity**: We measure what matters - to communities who design their own evaluation methodologies to act as mirrors for their unique narratives and rhythms.

### Responsibilities
We hold ourselves accountable to answering the following questions:  
1. What are alternate forms of data on diverse value contributions? How best can they be authentically reflected?
2. How can a regenerative evaluation process be conducted? What does the system look like?
3. Can multi-capital forms of value reading enable holistic evaluation? What does that look like
4. Can the threshold for active, playful participation in the evaluation processes be lowered? Which tools & practices enable this? 

## **Implementation**

Our evaluation methodology translates vision into action through a structured yet adaptable framework. This framework comprises three core components—**Container**, **Playground**, and **Instruments**—each designed to harmonize universal principles with contextual specificity.

### **Container**

The Container defines the logistical boundaries within which evaluation unfolds. These elements remain consistent across contexts, though their specific expressions adapt to local realities:

- **When (Timing of Data Collection)**:
    
    - **Responsive**: Triggered by regular programming activities.
        
    - **Periodic**: Scheduled at regular intervals for continuous insight.
        
    - **Emergent**: Activated by unforeseen events or shifts.
        
- **Which (Data Collection Touchpoints)**:
    
    - **Verbose Input**: Narrative reflections, qualitative feedback.
        
    - **Point Systems**: Quantitative rankings, ratings.
        
    - **Programmatic Data**: Structured submissions, sensor-derived metrics.
        
- **Who (Value-Generating Entities)**:
    
    - **Individuals**: Sovereign agents contributing personal insights and actions.
        
    - **Communities**: Stakeholder groups collectively generating value.
        
    - **Systems**: Broader processes and dynamics understood through ongoing interactions.
        

Together, these logistical parameters form a stable yet flexible container within which evaluation practices are embedded.

### **Playground**

Within this container lies the Playground—an exploratory space where stakeholders identify, articulate, and experiment with forms of value generation. The Playground is customizable, shaped by community priorities and evolving needs:

- **What (Forms of Valued Contributions)**:
    
    - **Activities**: Efforts invested in tangible actions and initiatives.
        
    - **Knowledge**: Documentation, insights shared from past experiences.
        
    - **Space**: Hosting engagements, facilitating connections within networks.
        
- **Why (Purpose Behind Valuation)**:
    
    - **Regenerative Shifts**: Catalyzing systemic transformations toward sustainability.
        
    - **Organizational Growth**: Enhancing collective capacities and resilience.
        
    - **Outputs Generated**: Tangible results emerging from collaborative efforts.
        
- **How (Visibility of Value Flow)**:
    
    - **Actions**: Observable behaviors captured via direct observation or technology.
        
    - **Reflections**: Personal narratives and subjective stakeholder experiences.
        
    - **Attributions**: Peer recognition highlighting contributions across dimensions.
        

These variables serve as illustrative templates that communities adapt to reflect their unique contexts and aspirations, fostering playful experimentation and authentic learning journeys.

### **Instruments**

The Instruments operationalize the evaluation process, providing dimensionality and depth through structured stages, technological tools, and analytical lenses:

- **Stages of Delivery**:
    
    - **Baselining**: Establishing an initial understanding of systemic conditions before intensive engagement begins.
        
    - **Reading**: Capturing data dynamically during active programming phases.
        
    - **Inferencing**: Synthesizing insights post-intensive to inform future actions.
        
- **Technological Tools Employed**:
    
    - **Telegram Bots**: Facilitating real-time collection of subjective data from stakeholders.
        
    - **Data Repositories**: Centralized platforms (e.g., GitHub repositories, wikis) for structured data aggregation.
        
    - **AI-enabled Analysis & Timelining**: Leveraging artificial intelligence to interpret complex multi-capital flows and generate actionable insights.
        
- **Analytical Dimensions Plotted Against**:
    
    - **Aspects**: Three to seven primary modes through which value generation is expressed and tracked.
        
    - **Capitals**: Five to ten resource categories mobilized within the action-learning journey context.
        
    - **Spheres**: Realms within systems where evolutionary change is observed and evaluated.
        

These instruments collectively enable nuanced understanding of value generation dynamics, supporting informed decision-making and adaptive learning.

### **Framework in Action**

In practice, our methodology unfolds iteratively:

Beginning with the Baselining stage, facilitators collaborate closely with stakeholders to map out the current state across five systemic spheres relevant to the community. Together they identify key activities—termed Aspects—that serve as focal points for understanding how value is generated. Stakeholders engage actively with these Aspects throughout the programming cycle, mobilizing diverse forms of capital aligned with their collective goals.

As activities unfold—whether planned or emergent—data collection occurs continuously through accessible technological channels such as Telegram bots, alongside facilitator observations. The data gathered feeds into centralized repositories where AI-driven analysis illuminates multi-capital flows in real-time. These insights are then integrated back into facilitation processes, enhancing stakeholder participation and enabling agile responsiveness to emerging patterns of collective evolution.

---
