import { PageGate } from '@/components/PageGate'
import { Tabs } from 'nextra/components'
import GraphRenderer from '@/components/GraphRenderer'

# Pilot Engagement

> This page is a response to the following questions:
> 
> What's our offer?
>
> How easy is it to set up/ how does it work?
>
> What's our business model/ our ask?

<PageGate requiredPassword="transition-labs-2025">

	We propose co-creating a pilot that sets up ChatALJ for an upcoming Transition Lab. This pilot will focus on enhancing North Star Transition’s capacity to capture, connect, and act on the wealth of insight generated in these multi-stakeholder settings.

	## What is ChatALJ?

	### Overview

	ChatALJ is the name given to the app currently living on our [evaluate.prisma.events](https://evaluate.prisma.events) subdomain. It's an interface to make visible and query the voice-based [timelining](/processes/process-infrastructuring/timelining) contributions made during an [action-learning journey](/patterns/action-learning%20journeys) (read "Transition Lab"). 

	### Setup
	It's built to be deployed to a partner on their own evaluate subdomain - <span className="text-[#7faec2]">evaluate.northstartransition.org</span>, for example. Depending on if the partner organisation has/ plans to have in-house software development capacity, they can either deploy it to their own infrastructure, or we can temporarily manage that for them (Prisma is designed for partners to manage their own infrastructure).

	One example of this is our long-term partner, Wada, who are using our apps to organise a hackathon in [Nairobi](/events/nairobi) with [register.wada.org](https://register.wada.org) and [docs.wada.org](https://docs.wada.org). These app deployments took less than a week, as it was mostly just branding and copy. Timelining and ChatALJ are more involved. 

	### Timelining Contributions
	Given the relatively boundless nature of voice as a medium of expression, in which you can convey all sorts of information, the particular use-case to which timelining is applied is decided by the kind of data you'd like to record. 
	
	In the case provided as an example at [evaluate](https://evaluate.prisma.events), the data modelling is relatively minimal: 
	<Tabs items={['Schema', 'Visualisation']}> 
	<Tabs.Tab>
	```
	// NODES
	Node Labels: ['Entry', 'Participant', 'TelegramChat', 'Voice', 'TextContent', 'Video', 'Photo', 'Entity', 'CaptionContent', 'VideoNote']


	// EDGES
	Entry -[SENT_BY]-> Participant
	Entry -[FROM_CHAT]-> TelegramChat
	Entry -[HAS_VOICE]-> Voice
	Entry -[HAS_TEXT]-> TextContent
	Entry -[HAS_VIDEO]-> Video
	Entry -[HAS_PHOTO]-> Photo
	Entry -[HAS_ENTITY]-> Entity
	Entry -[HAS_CAPTION]-> CaptionContent
	Entry -[HAS_VIDEO_NOTE]-> VideoNote
	```
	</Tabs.Tab>
	<Tabs.Tab>
	<GraphRenderer 
		nodes={[
			{ data: { id: 'TelegramChat', label: 'TelegramChat' } },
			{ data: { id: 'Entry1', label: 'Entry' } },
			{ data: { id: 'Entry2', label: 'Entry' } },
			{ data: { id: 'Entry3', label: 'Entry' } },
			{ data: { id: 'Participant1', label: 'Participant' } },
			{ data: { id: 'Participant2', label: 'Participant' } },
			{ data: { id: 'Participant3', label: 'Participant' } },
			{ data: { id: 'Voice1', label: 'Voice' } },
			{ data: { id: 'Voice2', label: 'Voice' } },
			{ data: { id: 'TextContent1', label: 'TextContent' } },
			{ data: { id: 'TextContent2', label: 'TextContent' } },
			{ data: { id: 'Video1', label: 'Video' } },
			{ data: { id: 'Photo1', label: 'Photo' } },
			{ data: { id: 'Entity1', label: 'Entity' } },
			{ data: { id: 'CaptionContent1', label: 'CaptionContent' } },
			{ data: { id: 'VideoNote1', label: 'VideoNote' } }
		]}
		edges={[
			{ data: { id: 'chat-entry1', source: 'TelegramChat', target: 'Entry1', label: 'FROM_CHAT' } },
			{ data: { id: 'chat-entry2', source: 'TelegramChat', target: 'Entry2', label: 'FROM_CHAT' } },
			{ data: { id: 'chat-entry3', source: 'TelegramChat', target: 'Entry3', label: 'FROM_CHAT' } },
			{ data: { id: 'entry1-participant1', source: 'Entry1', target: 'Participant1', label: 'SENT_BY' } },
			{ data: { id: 'entry2-participant2', source: 'Entry2', target: 'Participant2', label: 'SENT_BY' } },
			{ data: { id: 'entry3-participant3', source: 'Entry3', target: 'Participant3', label: 'SENT_BY' } },
			{ data: { id: 'entry1-voice1', source: 'Entry1', target: 'Voice1', label: 'HAS_VOICE' } },
			{ data: { id: 'entry2-text1', source: 'Entry2', target: 'TextContent1', label: 'HAS_TEXT' } },
			{ data: { id: 'entry3-voice2', source: 'Entry3', target: 'Voice2', label: 'HAS_VOICE' } },
			{ data: { id: 'entry1-video1', source: 'Entry1', target: 'Video1', label: 'HAS_VIDEO' } },
			{ data: { id: 'entry2-photo1', source: 'Entry2', target: 'Photo1', label: 'HAS_PHOTO' } },
			{ data: { id: 'entry3-text2', source: 'Entry3', target: 'TextContent2', label: 'HAS_TEXT' } },
			{ data: { id: 'entry1-entity1', source: 'Entry1', target: 'Entity1', label: 'HAS_ENTITY' } },
			{ data: { id: 'entry2-caption1', source: 'Entry2', target: 'CaptionContent1', label: 'HAS_CAPTION' } },
			{ data: { id: 'entry3-videonote1', source: 'Entry3', target: 'VideoNote1', label: 'HAS_VIDEO_NOTE' } }
		]}
		styleOverrides={[
			{
				selector: 'node',
				style: {
					'width': 30,
					'height': 30,
					'font-size': '16px',
					'font-weight': 'bold',
					'text-opacity': 1,
				}
			},
			{
				selector: 'edge',
				style: {
					width: 3,
					'opacity': 0.9,
					'line-color': '#333',
					'target-arrow-color': '#333',
					'target-arrow-shape': 'triangle',
					'arrow-scale': 1.2,
					'font-size': '12px',
					'font-weight': 'bold',
					color: '#333',
					'text-opacity': 1,
				}
			}
		]}
	/>
	</Tabs.Tab>
	<Tabs.Tab>
	
	</Tabs.Tab>
	</Tabs>

	As you can see, other media in addition to voice are also handled - photos, videos, and entities (mentions, links and tags) - however, it is predominantly the voice notes that are of interest, due to the dual nature of reliably extractable information (via transcriptions) as well as qualitative context (audio). 



	## Pilot Objectives
	
	1. ### Strengthen the hub relationship
		- 	Develop trust and alignment with the selected regional hub hosting the Transition Lab.
	2. ### Integrate hub & methodology into ChatALJ
		- Configure the technology to reflect both the hub’s priorities and North Star’s methodological approach.
	3. ### Deploy infrastructure & onboard participants
		- Provide the technical and operational setup for ChatALJ, including participant onboarding to timelining practices.
	4. ### Enable data capture & deep analysis
		- Support structured, high-quality data collection (voice notes, transcriptions, mapped connections) and apply advanced analysis to reveal systemic patterns, leverage points, and opportunities for coordinated action.

	## Case-studies as Developmental Accounts

	## Pilot Offer

	### Investment: To be decided together
	### Scope: ChatALJ deployment for one selected Transition Lab event
	### Outcomes:
	- Tested, ready-to-scale integration of ChatALJ into North Star’s Transition Lab process.
	- Enhanced capacity for systemic insight mapping and strategic follow-through across regions.
	- A documented case study for replication across other labs and regions.

</PageGate>